{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "af5b9358f624b7a10e69b5311cbd31159d36e52e31ed36b18bb11cfc0c99bfa2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "data = pd.read_excel(\"data/cleaned_data.xlsx\")\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "## stopwords from https://github.com/stopwords-iso/stopwords-de/blob/master/raw/stopwords-filter-de.txt\n",
    "stopwords = pd.read_excel(\"data/stopwords.xlsx\", header=None)[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=8, random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "god_string = \" \".join(data[\"topic\"])\n",
    "\n",
    "# vectorizer object\n",
    "count_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words=stopwords)\n",
    "doc_term_matrix = count_vect.fit_transform(data[\"topic\"].values.astype('U'))\n",
    "# LDA object for clustering topics\n",
    "LDA = LatentDirichletAllocation(n_components=8, random_state=42)\n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 10 words for topic #0:\n",
      "['usa', 'gipfel', 'brexit', 'eu', 'gestorben']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['em', 'wm', 'ergebnisse', 'bundesliga', 'fußball']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['türkei', 'corona', 'griechenland', 'is', 'syrien']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['csu', 'union', 'cdu', 'merkel', 'spd']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['kommentar', 'meldungen', 'überblick', 'weitere', 'wetter']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['reaktionen', 'tote', 'eu', 'meinung', 'lottozahlen']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['ägypten', 'ukraine', 'tag', 'machtkampf', 'sport']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['eu', 'formel', 'trump', 'präsident', 'us']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing top words for each cluster\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-5:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster topics and save to file\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "data['cluster'] = topic_values.argmax(axis=1)\n",
    "data.to_excel(\"data/cleaned_data.xlsx\", index=False)"
   ]
  }
 ]
}